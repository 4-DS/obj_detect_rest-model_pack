{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2db3c-570a-4520-97f9-e99b7cce1377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67358494-16f1-4179-9182-986945b729c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load pipeline and step parameters - do not edit\n",
    "from sinara.substep import get_pipeline_params, get_step_params\n",
    "pipeline_params = get_pipeline_params(pprint=True)\n",
    "step_params = get_step_params(pprint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca2677e-6dbf-49cb-94cf-55ab34553123",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# specify substep parameters for interactive run\n",
    "# this cell will be replaced during job run with the parameters from json within params subfolder\n",
    "substep_params={\n",
    "    'save_best': False,\n",
    "    'device': \"cuda:0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0a075-eca9-4b7a-ab12-457a84f5dbb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define substep interface\n",
    "from sinara.substep import NotebookSubstep, ENV_NAME, PIPELINE_NAME, ZONE_NAME, STEP_NAME, RUN_ID, ENTITY_NAME, ENTITY_PATH, SUBSTEP_NAME\n",
    "\n",
    "substep = NotebookSubstep(pipeline_params, step_params, substep_params)\n",
    "\n",
    "substep.interface(\n",
    "    inputs =\n",
    "    [ \n",
    "      { STEP_NAME: \"model_train\", ENTITY_NAME: \"obj_detect_inference_files\"} # stored detector files from train step\n",
    "    ],\n",
    "    \n",
    "    tmp_entities =\n",
    "    [\n",
    "        { ENTITY_NAME: \"obj_detect_inference_files\" }, # temporary detector files from train step\n",
    "        { ENTITY_NAME: \"obj_detect_onnx_files\"}, # temporary detector onnx files after converting \n",
    "    ],\n",
    "    \n",
    "    outputs =\n",
    "    [\n",
    "        { ENTITY_NAME: \"bento_service\" } # stored BentoService\n",
    "    ],\n",
    ")\n",
    "\n",
    "substep.print_interface_info()\n",
    "\n",
    "substep.exit_in_visualize_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114cb21-c454-4066-bdf1-b661d623e98c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify all notebook wide libraries imports here\n",
    "# Sinara lib imports is left in the place of their usage\n",
    "import json\n",
    "import os\n",
    "import os.path as osp\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import onnxruntime, pickle, shutil\n",
    "\n",
    "from mmengine.config import Config as MmConfig\n",
    "from mmdeploy.backend.sdk.export_info import export2SDK\n",
    "from mmdeploy.apis import torch2onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a55f1-6203-46b0-89f9-aed0cafb18f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run spark\n",
    "from sinara.spark import SinaraSpark\n",
    "from sinara.archive import SinaraArchive\n",
    "\n",
    "spark = SinaraSpark.run_session(0)\n",
    "archive = SinaraArchive(spark)\n",
    "SinaraSpark.ui_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ea64bc-5c73-4766-b3a0-6bad6c94caf1",
   "metadata": {},
   "source": [
    "### Loading obj_detect_inference_files from the model_train step \n",
    "(weights, configs, test image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060677f-4ae3-451c-8122-af898fd754a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = substep.inputs(step_name = \"model_train\")\n",
    "tmp_entities = substep.tmp_entities()\n",
    "# copy config from previos step to outputs\n",
    "\n",
    "archive.unpack_files_from_store_to_tmp(store_path=inputs.obj_detect_inference_files, tmp_entity_dir=tmp_entities.obj_detect_inference_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cccaf57-5e98-40fd-98d1-e9b6b58c788a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select obj_detector weights for converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae96ad73-dabb-478c-a2d1-488f78b77761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selecting a weights file to convert to onnx format (best, latest epoch, etc.)\n",
    "\n",
    "best_weights_pths = glob.glob(f\"{tmp_entities.obj_detect_inference_files}/*best*\")\n",
    "latest_weights_pths = glob.glob(f\"{tmp_entities.obj_detect_inference_files}/*latest*\")\n",
    "\n",
    "weights_pths = best_weights_pths if substep_params['save_best'] and len(best_weights_pths) > 0 else latest_weights_pths\n",
    "\n",
    "weights_pths.sort(key=lambda file: osp.getmtime(file))\n",
    "\n",
    "selected_weights_pth = weights_pths[-1]\n",
    "mmengine_cfg_path = osp.join(tmp_entities.obj_detect_inference_files, \"last_cfg.py\")\n",
    "mmengine_cfg = MmConfig.fromfile(mmengine_cfg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed8cec8-21f2-4607-b7ad-49310164c9f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Export to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163ed47-36ee-4bda-b4a7-6a9c92754f55",
   "metadata": {},
   "source": [
    "#### Preparing obj_detector weights for export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c55f386-85dd-4c67-b6e3-6cde0f54d92b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean model weigths - delete data of optimizer\n",
    "\n",
    "state_dict = torch.load(selected_weights_pth, map_location=torch.device('cpu'))\n",
    "\n",
    "print(f\"{state_dict.keys()=}\")\n",
    "if \"optimizer\" in state_dict:\n",
    "    del state_dict[\"optimizer\"]\n",
    "    \n",
    "clean_weigths_pth = osp.splitext(selected_weights_pth)[0]+\"_clean.pth\"\n",
    "torch.save(state_dict, clean_weigths_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4cbe81-acbc-4769-916f-3fdff9c8c81c",
   "metadata": {},
   "source": [
    "#### Setting up basic model training mmdeploy config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cadfb23-12c6-47eb-a0df-979ca70ddd3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_params = step_params[\"export_params\"]\n",
    "\n",
    "mmdeploy_cfg_path = osp.join(osp.expanduser(\"~\"), 'mmdeploy', 'configs', 'mmdet', 'detection', 'detection_onnxruntime_dynamic.py')\n",
    "mmdeploy_cfg = MmConfig.fromfile(mmdeploy_cfg_path)\n",
    "\n",
    "# set converting onnx file name\n",
    "mmdeploy_cfg.save_file = os.path.basename(clean_weigths_pth).split(\".\")[0] + \".onnx\"\n",
    "# set parameters NMS for export to onnx \n",
    "mmdeploy_cfg.codebase_config.post_processing.iou_threshold = export_params[\"iou_threshold\"]\n",
    "mmdeploy_cfg.codebase_config.post_processing.keep_top_k = export_params[\"keep_top_k\"]\n",
    "mmdeploy_cfg.codebase_config.post_processing.max_output_boxes_per_class = export_params[\"max_output_boxes_per_class\"]\n",
    "mmdeploy_cfg.codebase_config.post_processing.pre_top_k = export_params[\"pre_top_k\"]\n",
    "mmdeploy_cfg.codebase_config.post_processing.score_threshold = export_params[\"score_threshold\"]\n",
    "\n",
    "# output information for mmdeploy\n",
    "export2SDK( deploy_cfg=mmdeploy_cfg,\n",
    "            model_cfg=mmengine_cfg,\n",
    "            work_dir=tmp_entities.obj_detect_onnx_files,\n",
    "            pth=clean_weigths_pth,\n",
    "            device=substep_params['device'])\n",
    "\n",
    "# reopen config of model\n",
    "# fix bug in mmdeploy: after export2SDK changes model_cfg with error (use attributes size in augmentation, use Collect in preprocessing)\n",
    "mmengine_cfg = MmConfig.fromfile(mmengine_cfg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e3c780-f2ff-42a6-9ce0-197928f54025",
   "metadata": {},
   "source": [
    "#### Converting to onnx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bcd947-2a00-4ed6-8550-bc3e0762c2a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_img = np.zeros(list(mmengine_cfg.img_size)+[3], dtype=np.uint8)  # image zeros by shape [width, height, chanels]\n",
    "\n",
    "torch2onnx(img=dummy_img,\n",
    "           work_dir=tmp_entities.obj_detect_onnx_files,\n",
    "           save_file=mmdeploy_cfg.save_file,\n",
    "           deploy_cfg=mmdeploy_cfg,\n",
    "           model_cfg=mmengine_cfg,\n",
    "           model_checkpoint=clean_weigths_pth,\n",
    "           device=substep_params['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a0af3-4074-4a5b-a4f6-42ef98e7387d",
   "metadata": {},
   "source": [
    "### Pack to REST BentoService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47bf3ef-76b7-4312-ac09-b6c79cf06b44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bento_service import ModelService\n",
    "from pre_post_processing import PrePostProcessing\n",
    "\n",
    "CLASSES = mmengine_cfg.metainfo.CLASSES\n",
    "INPUT_SIZE = mmengine_cfg.img_size\n",
    "CATEGORIES = [{\"id\": class_id+1, \"name\": class_name} for class_id, class_name in enumerate(CLASSES)]\n",
    "\n",
    "outputs = substep.outputs()\n",
    "\n",
    "# copy test image \n",
    "test_image_path = osp.join(tmp_entities.obj_detect_inference_files, \"test.jpg\")\n",
    "onnx_test_image_path =  osp.join(tmp_entities.obj_detect_onnx_files, \"test.jpg\")\n",
    "shutil.copy(test_image_path, onnx_test_image_path)\n",
    "assert osp.exists(onnx_test_image_path)\n",
    "\n",
    "# inicialize onnx model\n",
    "onnx_file = os.path.join(tmp_entities.obj_detect_onnx_files, mmdeploy_cfg.save_file)\n",
    "assert osp.exists(onnx_file)\n",
    "ort_session = onnxruntime.InferenceSession(onnx_file, providers=['CPUExecutionProvider'])\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "output_name = [out.name for out in ort_session.get_outputs()]\n",
    "\n",
    "# read test image and processing for inference by onnx\n",
    "pre_post_processing = PrePostProcessing()\n",
    "input_data, scale_factors, img_ori_size = pre_post_processing.prep_processing(onnx_test_image_path, input_size=INPUT_SIZE)\n",
    "\n",
    "# inference onnx by test image\n",
    "outs = ort_session.run(output_name, {input_name: input_data})\n",
    "outs = pre_post_processing.post_processing(outs, scale_factors, img_ori_size, categories=CATEGORIES)\n",
    "\n",
    "# save and reopen pickle file output of inference by test image\n",
    "with open(osp.join(tmp_entities.obj_detect_onnx_files, 'test_result.pkl'), 'wb') as pkl_file:\n",
    "    pickle.dump(outs, pkl_file)    \n",
    "with open(osp.join(tmp_entities.obj_detect_onnx_files, 'test_result.pkl'), 'rb') as f_id:\n",
    "    test_result = f_id.read()    \n",
    "    \n",
    "# open test image\n",
    "with open(onnx_test_image_path, 'rb') as f_id:\n",
    "    test_image = f_id.read()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51a4e94-24bd-45aa-801f-f45be444a118",
   "metadata": {},
   "source": [
    "#### Packaging obj_detector files to bento_service artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43b1b2-eef4-426a-aa14-1ab4b0af46f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_service = ModelService()\n",
    "model_service.pack('model', onnx_file)\n",
    "model_service.pack('test_image', test_image)\n",
    "model_service.pack('test_result', test_result)    \n",
    "model_service.pack('categories', CATEGORIES)\n",
    "model_service.pack('input_size', INPUT_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b3171-c23d-4bff-83da-96a4900ca2e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Send packaged onnx_obj_detector to outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9fe07f-fcd5-4d03-886b-dbdf4b60db64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model as a bento pack\n",
    "from sinara.bentoml import save_bentoservice\n",
    "save_bentoservice(model_service, path=outputs.bento_service, substep=substep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6aec1-7ca6-40b7-965e-07da5ee26b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stop spark\n",
    "SinaraSpark.stop_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
